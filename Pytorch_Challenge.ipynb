{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hTJnJXgI4-5S"
   },
   "source": [
    "## Convolutional Nerual Network Flower Species Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports here\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets,models,transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "\n",
    "import json\n",
    "\n",
    "%matplotlib inline\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading and model defining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define hyper-parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KJ19ku9t5A2Y"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_worker = 4\n",
    "learn_rate = 0.002\n",
    "N_epochs = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zg3JAKnfUylW"
   },
   "source": [
    "For the trainning images, apply transformations such as random scaling, cropping, and flipping. The helps to generalize the data and increase validation accuracy. To make use of pre-trained models from ImageNet, images has to be 224x224, with normalized means and standard deviations of [0.485, 0.456, 0.406] and [0.229, 0.224, 0.225] for [R,G,B],respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uipHENyZ5GFu"
   },
   "outputs": [],
   "source": [
    "data_dir = '/content/drive/My Drive/Colab Notebooks/flower_data'\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]), \n",
    "}\n",
    "image_datasets = {\n",
    "                x: datasets.ImageFolder(os.path.join(data_dir,x),data_transforms[x]) for x in ['train','valid']\n",
    "}\n",
    "dataloaders = {\n",
    "                x: torch.utils.data.DataLoader(image_datasets[x], batch_size = batch_size, shuffle = True, num_workers = num_worker)\n",
    "                for x in ['train','valid']\n",
    "}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'valid']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pretrained Resnet152 is used to build the classifier model, the CNN part of the model is frozen, and the FC part of the model is redefined. The trainning process will only update the weights for the newly defined FC layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bh2mu-Rg5rbN"
   },
   "outputs": [],
   "source": [
    "ClassifierModel = models.resnet152(pretrained = True)\n",
    "for param in ClassifierModel.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "num_ftr = ClassifierModel.fc.in_features\n",
    "ClassifierModel.fc = nn.Sequential(\n",
    "                                    nn.Linear(num_ftr,1000),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Dropout(0.2),\n",
    "                                    nn.Linear(1000,102)\n",
    "                                  )\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#optimizer = optim.Adam(ClassifierModel.classifier.parameters(),lr = learn_rate)\n",
    "optimizer = optim.SGD(ClassifierModel.fc.parameters(),lr = learn_rate,momentum = 0.9)\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=0.8*N_epochs, gamma=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hBDwupOt5zSB"
   },
   "outputs": [],
   "source": [
    "#---------------------define device-----------------------#\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\" )\n",
    "ClassifierModel.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sxsjj9GZ535u"
   },
   "outputs": [],
   "source": [
    "#------------------helper function : model train------------------#\n",
    "def train_model(model,criterion, optimizer, scheduler, num_epochs):\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    batch = 0\n",
    "    best_epoch = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-'*10)\n",
    "        start_epoch = time.time()\n",
    "        \n",
    "        #each epoch has trainning and validation phase\n",
    "        for phase in ['train','valid']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()\n",
    "            else :\n",
    "                model.eval()\n",
    "                \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            \n",
    "            #iterate over data\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                start_batch = time.time()\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                batch += 1\n",
    "                #zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                #forward prop.\n",
    "                with torch.set_grad_enabled(phase=='train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _,preds = torch.max(outputs,1)\n",
    "                    loss = criterion(outputs,labels)\n",
    "                    \n",
    "                #backward prop.\n",
    "                    if phase =='train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                #statistics\n",
    "                running_loss +=loss.item()*inputs.size(0)\n",
    "                running_corrects +=torch.sum(preds == labels.data)\n",
    "                #print('Batch {} : {}'.format(batch,time.time() - start_batch))\n",
    "                \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase,epoch_loss,epoch_acc))\n",
    "                  #'Epoch_time:',time.time()-start_epoch)\n",
    "                 \n",
    "            \n",
    "            # deep copy the model\n",
    "            if phase == 'valid' and epoch_acc > best_acc :\n",
    "                best_epoch = epoch\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                \n",
    "    print('Best val Acc: {:4f} at epoch {}'.format(best_acc,best_epoch+1))\n",
    "            \n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y5cR_Kcs58As"
   },
   "outputs": [],
   "source": [
    "# ---------------------train the model to get a good classifier--------------------------#\n",
    "ClassifierModel = train_model(ClassifierModel, criterion, optimizer, exp_lr_scheduler,\n",
    "                       num_epochs=N_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J0sH25i59Ipq"
   },
   "outputs": [],
   "source": [
    "with open('/content/drive/My Drive/Colab Notebooks/cat_to_name.json', 'r') as f:\n",
    "    class_names = json.load(f)\n",
    "  \n",
    "ClassifierModel.class_to_idx = image_datasets['train'].class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Ee8zLI4EfAd"
   },
   "outputs": [],
   "source": [
    "#-------------------------save the model for resumming training or inference---------------------#\n",
    "torch.save({\n",
    "            'epoch': 60,\n",
    "            'model_state_dict': ClassifierModel.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict()\n",
    "            \n",
    "            }, '/content/drive/My Drive/Colab Notebooks/Classifier_Resnet152.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 8296
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5680,
     "status": "ok",
     "timestamp": 1546557603310,
     "user": {
      "displayName": "Lee Young",
      "photoUrl": "",
      "userId": "15107526857504309725"
     },
     "user_tz": 300
    },
    "id": "EKzqr7Uxh028",
    "outputId": "91c6e640-5407-4e05-bc29-aa8790a49de4"
   },
   "outputs": [],
   "source": [
    "#------------------------load the model for resumming training or inference-----------------------#\n",
    "TestModel = models.resnet152(pretrained = True)\n",
    "for param in TestModel.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "num_ftr = TestModel.fc.in_features\n",
    "TestModel.fc = nn.Sequential(\n",
    "                                    nn.Linear(num_ftr,1000),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Dropout(0.2),\n",
    "                                    nn.Linear(1000,102)\n",
    "                                  )\n",
    "\n",
    "TestOptimizer = optim.SGD(TestModel.fc.parameters(),lr = learn_rate,momentum = 0.9)\n",
    "\n",
    "checkpoint = torch.load('/content/drive/My Drive/Colab Notebooks/Classifier_Resnet152.pth')\n",
    "TestModel.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "TestModel.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1442,
     "status": "ok",
     "timestamp": 1546557626633,
     "user": {
      "displayName": "Lee Young",
      "photoUrl": "",
      "userId": "15107526857504309725"
     },
     "user_tz": 300
    },
    "id": "3qW5bkxv_YJq",
    "outputId": "a8b3fed0-6506-4e7f-c31e-9bef2f2efbff"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "test_data_dir = '/content/drive/My Drive/Colab Notebooks/flower_data/test'\n",
    "pil_image = Image.open('/content/drive/My Drive/Colab Notebooks/flower_data/test/7/image_07216.jpg')\n",
    "plt.imshow(pil_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 819,
     "status": "ok",
     "timestamp": 1546557632736,
     "user": {
      "displayName": "Lee Young",
      "photoUrl": "",
      "userId": "15107526857504309725"
     },
     "user_tz": 300
    },
    "id": "hefT9Ze4McgP",
    "outputId": "0ff6f7a0-9f37-407e-8304-28d764378ef4"
   },
   "outputs": [],
   "source": [
    "def process_image(pil_image):\n",
    "    #resize the image with shorter side of 256 px\n",
    "    width, height = pil_image.size\n",
    "    if width <= height :\n",
    "      pil_image.thumbnail((256*float(height/width),256*float(height/width)))\n",
    "    else :\n",
    "      pil_image.thumbnail((256*float(width/height),256*float(width/height)))\n",
    "      \n",
    "    # center crop the image with 224 px\n",
    "    width, height = pil_image.size \n",
    "    left = np.ceil((width - 224)/2)\n",
    "    top = np.ceil((height - 224)/2)\n",
    "    right = np.ceil((width + 224)/2)\n",
    "    bottom = np.ceil((height + 224)/2)\n",
    "    pil_image = pil_image.crop((left, top, right, bottom))\n",
    "    \n",
    "    # To Tensor\n",
    "    np_image = np.array(pil_image)/255\n",
    "    \n",
    "    # Normalize\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    np_image = (np_image - mean)/std\n",
    "    \n",
    "    # transpose the color channel\n",
    "    np_image = np.transpose(np_image,(2,0,1))\n",
    "    \n",
    "    return np_image\n",
    "    \n",
    "  \n",
    "np_image = process_image(pil_image)\n",
    "#plt.imshow(test_pil)\n",
    "print (np_image.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1332,
     "status": "ok",
     "timestamp": 1546557636847,
     "user": {
      "displayName": "Lee Young",
      "photoUrl": "",
      "userId": "15107526857504309725"
     },
     "user_tz": 300
    },
    "id": "4LTBviGIV3jw",
    "outputId": "2323fc66-3dd0-44f8-e387-e690b74c604b"
   },
   "outputs": [],
   "source": [
    "def imshow(image, ax=None, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    \n",
    "    # PyTorch tensors assume the color channel is the first dimension\n",
    "    # but matplotlib assumes is the third dimension\n",
    "    image = image.transpose((1, 2, 0))\n",
    "    \n",
    "    # Undo preprocessing\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    image = std * image + mean\n",
    "    \n",
    "    # Image needs to be clipped between 0 and 1 or it looks like noise when displayed\n",
    "    image = np.clip(image, 0, 1)\n",
    "    \n",
    "    ax.imshow(image)\n",
    "    \n",
    "    return ax\n",
    "  \n",
    "imshow(np_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1045,
     "status": "ok",
     "timestamp": 1546557641999,
     "user": {
      "displayName": "Lee Young",
      "photoUrl": "",
      "userId": "15107526857504309725"
     },
     "user_tz": 300
    },
    "id": "XV2KEGrdKE0e",
    "outputId": "9061fbd4-050d-4399-9878-fe17e865a3a7"
   },
   "outputs": [],
   "source": [
    "#--------------------Class Prediction------------------------------\n",
    "def predict(np_image, model, topk=5):\n",
    "    torch_image = torch.from_numpy(np_image).float()\n",
    "    torch_image = torch_image.unsqueeze(0)\n",
    "    scores = model(torch_image)   \n",
    "    m = nn.Softmax()\n",
    "    probs = m(scores)\n",
    "    Top_ps,Top_class = probs.topk(topk,dim=1)\n",
    "    \n",
    "    return Top_ps,Top_class\n",
    "  \n",
    "Tp_ps,Tp_cls = predict(np_image, TestModel)\n",
    "print(Tp_ps)\n",
    "print(Tp_cls)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Pytorch_Challenge_Prj(4).ipynb",
   "provenance": [
    {
     "file_id": "1ACgq6E_hFv4GHaFanI1XJ8ai4nLX3VKA",
     "timestamp": 1543977062245
    },
    {
     "file_id": "1VmPvXSBxXU3A3xJMlu34M4SwqS3tFfcn",
     "timestamp": 1543890109403
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
